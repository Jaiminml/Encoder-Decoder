{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eng to Hindi.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YQluqpuf1-d",
        "outputId": "8f92b77c-cdac-490c-d865-2ee756ca8451"
      },
      "source": [
        "cd drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1InLvQE4Okd"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U68Pt0z64QWq"
      },
      "source": [
        "batch_size = 64  # Batch size for training.\r\n",
        "epochs = 100  # Number of epochs to train for.\r\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space.\r\n",
        "num_samples = 10000  # Number of samples to train on.\r\n",
        "# Path to the data txt file on disk."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lnkeh8pP3fLK"
      },
      "source": [
        "hindi_sen = open('IITB.en-hi.hi').read().split(\"\\n\")[:-1]\r\n",
        "eng_sen = open('IITB.en-hi.en').read().split(\"\\n\")[:-1]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yb2-ZyUG37HD",
        "outputId": "2877eab2-a06f-4956-8489-0a83e6d425a7"
      },
      "source": [
        "hindi_sen[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['अपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें',\n",
              " 'एक्सेर्साइसर पहुंचनीयता अन्वेषक',\n",
              " 'निचले पटल के लिए डिफोल्ट प्लग-इन खाका',\n",
              " 'ऊपरी पटल के लिए डिफोल्ट प्लग-इन खाका',\n",
              " 'उन प्लग-इनों की सूची जिन्हें डिफोल्ट रूप से निष्क्रिय किया गया है',\n",
              " 'अवधि को हाइलाइट रकें',\n",
              " 'पहुंचनीय आसंधि (नोड) को चुनते समय हाइलाइट बक्से की अवधि',\n",
              " 'सीमांत (बोर्डर) के रंग को हाइलाइट करें',\n",
              " 'हाइलाइट किए गए सीमांत का रंग और अपारदर्शिता। ',\n",
              " 'भराई के रंग को हाइलाइट करें']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQaEoigGCpHl",
        "outputId": "0c7bec6b-af75-4bbf-efee-fcfa9f9d99d5"
      },
      "source": [
        "eng_sen[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Give your application an accessibility workout',\n",
              " 'Accerciser Accessibility Explorer',\n",
              " 'The default plugin layout for the bottom panel',\n",
              " 'The default plugin layout for the top panel',\n",
              " 'A list of plugins that are disabled by default',\n",
              " 'Highlight duration',\n",
              " 'The duration of the highlight box when selecting accessible nodes',\n",
              " 'Highlight border color',\n",
              " 'The color and opacity of the highlight border.',\n",
              " 'Highlight fill color']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZzvR0zPgQ92"
      },
      "source": [
        "import numpy as np\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD6764UyDUYP",
        "outputId": "ae8dc793-441d-4881-97b0-b25bf012f089"
      },
      "source": [
        "input_text = eng_sen[:10000]\r\n",
        "target_texts = hindi_sen[:10000]\r\n",
        "len(input_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPuoFEkvDuRH"
      },
      "source": [
        "target_text = []\r\n",
        "\r\n",
        "for i in target_texts:\r\n",
        "  target_text.append( \"\\t\" + i + \"\\n\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_Q2fvF1TFZ90",
        "outputId": "47a9cddc-298a-4ac3-ade2-0d201fd94e5d"
      },
      "source": [
        "target_text[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\tअपने अनुप्रयोग को पहुंचनीयता व्यायाम का लाभ दें\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkWzInRqFfjE",
        "outputId": "022775f0-9221-471d-924e-f0c288e5fdb1"
      },
      "source": [
        "print(len(input_text))\r\n",
        "print(len(target_text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYzccV7tF6J6"
      },
      "source": [
        "# Vectorize the data.\r\n",
        "input_characters = set()\r\n",
        "target_characters = set()\r\n",
        "for char in input_text:\r\n",
        "  for chars in char:\r\n",
        "    if chars not in input_characters:\r\n",
        "      input_characters.add(chars)\r\n",
        "for char in target_text:\r\n",
        "  for chars in char:\r\n",
        "    if chars not in target_characters:\r\n",
        "      target_characters.add(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKzEplzOGaGk",
        "outputId": "91b73615-f880-4c47-c0af-b4c77612de94"
      },
      "source": [
        "input_characters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " '!',\n",
              " '\"',\n",
              " '#',\n",
              " '%',\n",
              " '&',\n",
              " \"'\",\n",
              " '(',\n",
              " ')',\n",
              " '*',\n",
              " '+',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '<',\n",
              " '=',\n",
              " '>',\n",
              " '?',\n",
              " 'A',\n",
              " 'B',\n",
              " 'C',\n",
              " 'D',\n",
              " 'E',\n",
              " 'F',\n",
              " 'G',\n",
              " 'H',\n",
              " 'I',\n",
              " 'J',\n",
              " 'K',\n",
              " 'L',\n",
              " 'M',\n",
              " 'N',\n",
              " 'O',\n",
              " 'P',\n",
              " 'Q',\n",
              " 'R',\n",
              " 'S',\n",
              " 'T',\n",
              " 'U',\n",
              " 'V',\n",
              " 'W',\n",
              " 'X',\n",
              " 'Y',\n",
              " 'Z',\n",
              " '[',\n",
              " '\\\\',\n",
              " ']',\n",
              " '_',\n",
              " '`',\n",
              " 'a',\n",
              " 'b',\n",
              " 'c',\n",
              " 'd',\n",
              " 'e',\n",
              " 'f',\n",
              " 'g',\n",
              " 'h',\n",
              " 'i',\n",
              " 'j',\n",
              " 'k',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 'o',\n",
              " 'p',\n",
              " 'q',\n",
              " 'r',\n",
              " 's',\n",
              " 't',\n",
              " 'u',\n",
              " 'v',\n",
              " 'w',\n",
              " 'x',\n",
              " 'y',\n",
              " 'z',\n",
              " '~',\n",
              " '©',\n",
              " '“',\n",
              " '”',\n",
              " '…'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EA8uHqQOgTkO",
        "outputId": "0460f49a-4185-45a9-bb55-399dee82e776"
      },
      "source": [
        "input_characters = sorted(list(input_characters))\r\n",
        "target_characters = sorted(list(target_characters))\r\n",
        "num_encoder_tokens = len(input_characters)\r\n",
        "num_decoder_tokens = len(target_characters)\r\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_text])\r\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_text])\r\n",
        "\r\n",
        "print(\"Number of samples:\", len(input_text))\r\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\r\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\r\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\r\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\r\n",
        "\r\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\r\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 93\n",
            "Number of unique output tokens: 154\n",
            "Max sequence length for inputs: 233\n",
            "Max sequence length for outputs: 346\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r_1jQXAYfBC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "204b8eec-21b9-4e33-ac69-a33a37791a44"
      },
      "source": [
        "input_token_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 0,\n",
              " '!': 1,\n",
              " '\"': 2,\n",
              " '#': 3,\n",
              " '%': 4,\n",
              " '&': 5,\n",
              " \"'\": 6,\n",
              " '(': 7,\n",
              " ')': 8,\n",
              " '*': 9,\n",
              " '+': 10,\n",
              " ',': 11,\n",
              " '-': 12,\n",
              " '.': 13,\n",
              " '/': 14,\n",
              " '0': 15,\n",
              " '1': 16,\n",
              " '2': 17,\n",
              " '3': 18,\n",
              " '4': 19,\n",
              " '5': 20,\n",
              " '6': 21,\n",
              " '7': 22,\n",
              " '8': 23,\n",
              " '9': 24,\n",
              " ':': 25,\n",
              " ';': 26,\n",
              " '<': 27,\n",
              " '=': 28,\n",
              " '>': 29,\n",
              " '?': 30,\n",
              " 'A': 31,\n",
              " 'B': 32,\n",
              " 'C': 33,\n",
              " 'D': 34,\n",
              " 'E': 35,\n",
              " 'F': 36,\n",
              " 'G': 37,\n",
              " 'H': 38,\n",
              " 'I': 39,\n",
              " 'J': 40,\n",
              " 'K': 41,\n",
              " 'L': 42,\n",
              " 'M': 43,\n",
              " 'N': 44,\n",
              " 'O': 45,\n",
              " 'P': 46,\n",
              " 'Q': 47,\n",
              " 'R': 48,\n",
              " 'S': 49,\n",
              " 'T': 50,\n",
              " 'U': 51,\n",
              " 'V': 52,\n",
              " 'W': 53,\n",
              " 'X': 54,\n",
              " 'Y': 55,\n",
              " 'Z': 56,\n",
              " '[': 57,\n",
              " '\\\\': 58,\n",
              " ']': 59,\n",
              " '_': 60,\n",
              " '`': 61,\n",
              " 'a': 62,\n",
              " 'b': 63,\n",
              " 'c': 64,\n",
              " 'd': 65,\n",
              " 'e': 66,\n",
              " 'f': 67,\n",
              " 'g': 68,\n",
              " 'h': 69,\n",
              " 'i': 70,\n",
              " 'j': 71,\n",
              " 'k': 72,\n",
              " 'l': 73,\n",
              " 'm': 74,\n",
              " 'n': 75,\n",
              " 'o': 76,\n",
              " 'p': 77,\n",
              " 'q': 78,\n",
              " 'r': 79,\n",
              " 's': 80,\n",
              " 't': 81,\n",
              " 'u': 82,\n",
              " 'v': 83,\n",
              " 'w': 84,\n",
              " 'x': 85,\n",
              " 'y': 86,\n",
              " 'z': 87,\n",
              " '~': 88,\n",
              " '©': 89,\n",
              " '“': 90,\n",
              " '”': 91,\n",
              " '…': 92}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt2mATB2gyl2"
      },
      "source": [
        "encoder_input_data = np.zeros(\r\n",
        "    (len(input_text), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\r\n",
        ")\r\n",
        "decoder_input_data = np.zeros(\r\n",
        "    (len(input_text), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\r\n",
        ")\r\n",
        "decoder_target_data = np.zeros(\r\n",
        "    (len(input_text), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\r\n",
        ")\r\n",
        "\r\n",
        "for i, (input_texts, target_texts) in enumerate(zip(input_text, target_text)):\r\n",
        "    for t, char in enumerate(input_texts):\r\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\r\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\r\n",
        "    for t, char in enumerate(target_texts):\r\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\r\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\r\n",
        "        if t > 0:\r\n",
        "            # decoder_target_data will be ahead by one timestep\r\n",
        "            # and will not include the start character.\r\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\r\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\r\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVgqQDvNg2hI"
      },
      "source": [
        "# Define an input sequence and process it.\r\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\r\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\r\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\r\n",
        "\r\n",
        "# We discard `encoder_outputs` and only keep the states.\r\n",
        "encoder_states = [state_h, state_c]\r\n",
        "\r\n",
        "# Set up the decoder, using `encoder_states` as initial state.\r\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\r\n",
        "\r\n",
        "# We set up our decoder to return full output sequences,\r\n",
        "# and to return internal states as well. We don't use the\r\n",
        "# return states in the training model, but we will use them in inference.\r\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\r\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\r\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "\r\n",
        "# Define the model that will turn\r\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\r\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kijnDe3nhfxd",
        "outputId": "15c460e7-84f2-4bc2-938f-ea236fc5fe5c"
      },
      "source": [
        "model.compile(\r\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\r\n",
        ")\r\n",
        "model.fit(\r\n",
        "    [encoder_input_data, decoder_input_data],\r\n",
        "    decoder_target_data,\r\n",
        "    batch_size=batch_size,\r\n",
        "    epochs=epochs,\r\n",
        "    validation_split=0.2,\r\n",
        ")\r\n",
        "# Save model\r\n",
        "model.save(\"s2s\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "125/125 [==============================] - 19s 95ms/step - loss: 0.7462 - accuracy: 0.8970 - val_loss: 0.1871 - val_accuracy: 0.9639\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 11s 89ms/step - loss: 0.3045 - accuracy: 0.9404 - val_loss: 0.1567 - val_accuracy: 0.9650\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.3141 - accuracy: 0.9417 - val_loss: 0.1456 - val_accuracy: 0.9665\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.2133 - accuracy: 0.9467 - val_loss: 0.1289 - val_accuracy: 0.9681\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.1795 - accuracy: 0.9549 - val_loss: 0.1226 - val_accuracy: 0.9686\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.1545 - accuracy: 0.9602 - val_loss: 0.1164 - val_accuracy: 0.9702\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.1409 - accuracy: 0.9630 - val_loss: 0.1121 - val_accuracy: 0.9710\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.1234 - accuracy: 0.9674 - val_loss: 0.1067 - val_accuracy: 0.9718\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.1168 - accuracy: 0.9688 - val_loss: 0.1041 - val_accuracy: 0.9731\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.1088 - accuracy: 0.9709 - val_loss: 0.1043 - val_accuracy: 0.9726\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.1008 - accuracy: 0.9730 - val_loss: 0.1007 - val_accuracy: 0.9733\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 0.0933 - accuracy: 0.9750 - val_loss: 0.0988 - val_accuracy: 0.9742\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0885 - accuracy: 0.9764 - val_loss: 0.0973 - val_accuracy: 0.9744\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0827 - accuracy: 0.9781 - val_loss: 0.0954 - val_accuracy: 0.9753\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0766 - accuracy: 0.9798 - val_loss: 0.0953 - val_accuracy: 0.9754\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0735 - accuracy: 0.9808 - val_loss: 0.0916 - val_accuracy: 0.9763\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0708 - accuracy: 0.9819 - val_loss: 0.0912 - val_accuracy: 0.9768\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0652 - accuracy: 0.9832 - val_loss: 0.0906 - val_accuracy: 0.9769\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0621 - accuracy: 0.9838 - val_loss: 0.0880 - val_accuracy: 0.9775\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0581 - accuracy: 0.9849 - val_loss: 0.0874 - val_accuracy: 0.9777\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 0.0562 - accuracy: 0.9856 - val_loss: 0.0866 - val_accuracy: 0.9781\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0533 - accuracy: 0.9862 - val_loss: 0.0896 - val_accuracy: 0.9776\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0573 - accuracy: 0.9852 - val_loss: 0.0861 - val_accuracy: 0.9781\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0527 - accuracy: 0.9863 - val_loss: 0.0829 - val_accuracy: 0.9790\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0496 - accuracy: 0.9871 - val_loss: 0.0838 - val_accuracy: 0.9787\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0472 - accuracy: 0.9877 - val_loss: 0.0795 - val_accuracy: 0.9799\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0443 - accuracy: 0.9885 - val_loss: 0.0781 - val_accuracy: 0.9804\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0437 - accuracy: 0.9886 - val_loss: 0.0778 - val_accuracy: 0.9804\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0427 - accuracy: 0.9889 - val_loss: 0.0761 - val_accuracy: 0.9807\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0413 - accuracy: 0.9891 - val_loss: 0.0747 - val_accuracy: 0.9812\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0398 - accuracy: 0.9895 - val_loss: 0.0721 - val_accuracy: 0.9818\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0379 - accuracy: 0.9900 - val_loss: 0.0718 - val_accuracy: 0.9818\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0372 - accuracy: 0.9901 - val_loss: 0.0697 - val_accuracy: 0.9825\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0357 - accuracy: 0.9905 - val_loss: 0.0688 - val_accuracy: 0.9827\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 0.0355 - accuracy: 0.9906 - val_loss: 0.0671 - val_accuracy: 0.9834\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0349 - accuracy: 0.9906 - val_loss: 0.0667 - val_accuracy: 0.9832\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0339 - accuracy: 0.9908 - val_loss: 0.0651 - val_accuracy: 0.9837\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0341 - accuracy: 0.9908 - val_loss: 0.0636 - val_accuracy: 0.9842\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0325 - accuracy: 0.9911 - val_loss: 0.0617 - val_accuracy: 0.9848\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0320 - accuracy: 0.9912 - val_loss: 0.0612 - val_accuracy: 0.9848\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0317 - accuracy: 0.9912 - val_loss: 0.0607 - val_accuracy: 0.9849\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0306 - accuracy: 0.9915 - val_loss: 0.0598 - val_accuracy: 0.9850\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0302 - accuracy: 0.9916 - val_loss: 0.0581 - val_accuracy: 0.9856\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0297 - accuracy: 0.9917 - val_loss: 0.0577 - val_accuracy: 0.9858\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0296 - accuracy: 0.9917 - val_loss: 0.0564 - val_accuracy: 0.9859\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 0.0549 - val_accuracy: 0.9865\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0291 - accuracy: 0.9918 - val_loss: 0.0544 - val_accuracy: 0.9865\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0285 - accuracy: 0.9919 - val_loss: 0.0537 - val_accuracy: 0.9870\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0526 - val_accuracy: 0.9870\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0285 - accuracy: 0.9919 - val_loss: 0.0533 - val_accuracy: 0.9872\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0280 - accuracy: 0.9920 - val_loss: 0.0519 - val_accuracy: 0.9871\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0274 - accuracy: 0.9921 - val_loss: 0.0509 - val_accuracy: 0.9874\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0272 - accuracy: 0.9921 - val_loss: 0.0513 - val_accuracy: 0.9875\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0270 - accuracy: 0.9922 - val_loss: 0.0498 - val_accuracy: 0.9878\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 0.0267 - accuracy: 0.9923 - val_loss: 0.0489 - val_accuracy: 0.9881\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0480 - val_accuracy: 0.9885\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 0.0265 - accuracy: 0.9923 - val_loss: 0.0479 - val_accuracy: 0.9885\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0261 - accuracy: 0.9923 - val_loss: 0.0469 - val_accuracy: 0.9888\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 11s 85ms/step - loss: 0.0261 - accuracy: 0.9924 - val_loss: 0.0468 - val_accuracy: 0.9889\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.0466 - val_accuracy: 0.9888\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.0460 - val_accuracy: 0.9890\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0254 - accuracy: 0.9925 - val_loss: 0.0461 - val_accuracy: 0.9888\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0255 - accuracy: 0.9924 - val_loss: 0.0453 - val_accuracy: 0.9893\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0251 - accuracy: 0.9925 - val_loss: 0.0446 - val_accuracy: 0.9895\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.0456 - val_accuracy: 0.9890\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0252 - accuracy: 0.9925 - val_loss: 0.0445 - val_accuracy: 0.9894\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0249 - accuracy: 0.9926 - val_loss: 0.0439 - val_accuracy: 0.9896\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0252 - accuracy: 0.9926 - val_loss: 0.0435 - val_accuracy: 0.9897\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0247 - accuracy: 0.9926 - val_loss: 0.0433 - val_accuracy: 0.9895\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0245 - accuracy: 0.9926 - val_loss: 0.0433 - val_accuracy: 0.9896\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0256 - accuracy: 0.9925 - val_loss: 0.0431 - val_accuracy: 0.9895\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0243 - accuracy: 0.9926 - val_loss: 0.0425 - val_accuracy: 0.9899\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0421 - val_accuracy: 0.9898\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.0423 - val_accuracy: 0.9898\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0417 - val_accuracy: 0.9900\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0240 - accuracy: 0.9927 - val_loss: 0.0421 - val_accuracy: 0.9899\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 11s 88ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0411 - val_accuracy: 0.9901\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0412 - val_accuracy: 0.9902\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0239 - accuracy: 0.9927 - val_loss: 0.0421 - val_accuracy: 0.9898\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0237 - accuracy: 0.9928 - val_loss: 0.0413 - val_accuracy: 0.9902\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0407 - val_accuracy: 0.9901\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0405 - val_accuracy: 0.9902\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0236 - accuracy: 0.9928 - val_loss: 0.0406 - val_accuracy: 0.9901\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0412 - val_accuracy: 0.9901\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0404 - val_accuracy: 0.9902\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0235 - accuracy: 0.9927 - val_loss: 0.0402 - val_accuracy: 0.9904\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0234 - accuracy: 0.9928 - val_loss: 0.0399 - val_accuracy: 0.9903\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0233 - accuracy: 0.9929 - val_loss: 0.0407 - val_accuracy: 0.9904\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0233 - accuracy: 0.9928 - val_loss: 0.0400 - val_accuracy: 0.9903\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0235 - accuracy: 0.9928 - val_loss: 0.0399 - val_accuracy: 0.9903\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.0402 - val_accuracy: 0.9904\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.0393 - val_accuracy: 0.9904\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0232 - accuracy: 0.9929 - val_loss: 0.0399 - val_accuracy: 0.9903\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0232 - accuracy: 0.9928 - val_loss: 0.0399 - val_accuracy: 0.9903\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0400 - val_accuracy: 0.9904\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0397 - val_accuracy: 0.9902\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0228 - accuracy: 0.9929 - val_loss: 0.0392 - val_accuracy: 0.9905\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 0.0421 - val_accuracy: 0.9897\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 11s 86ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0397 - val_accuracy: 0.9904\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 11s 87ms/step - loss: 0.0230 - accuracy: 0.9928 - val_loss: 0.0391 - val_accuracy: 0.9906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNNl7dwwhiGc"
      },
      "source": [
        "# Define sampling models\r\n",
        "# Restore the model and construct the encoder and decoder.\r\n",
        "model = keras.models.load_model(\"s2s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3Z1ejVjPmj",
        "outputId": "96ad01eb-e77e-4c68-ee5e-bf0a822b6aec"
      },
      "source": [
        "model.input"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, None, 93) dtype=float32 (created by layer 'input_1')>,\n",
              " <KerasTensor: shape=(None, None, 154) dtype=float32 (created by layer 'input_2')>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxFw7fofjSB8",
        "outputId": "2bcac8e2-9cab-4b28-a756-f3707e009377"
      },
      "source": [
        "model.layers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f1dc2330fd0>,\n",
              " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x7f1d7d617cc0>,\n",
              " <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f1ddc286710>,\n",
              " <tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f1dc27c5d30>,\n",
              " <tensorflow.python.keras.layers.core.Dense at 0x7f1dc268ccc0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUxvqCQLh42h"
      },
      "source": [
        "encoder_inputs = model.input[0]  # input_1\r\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\r\n",
        "encoder_states = [state_h_enc, state_c_enc]\r\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\r\n",
        "\r\n",
        "decoder_inputs = model.input[1]  # input_2\r\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_5\")\r\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_6\")\r\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\r\n",
        "decoder_lstm = model.layers[3]\r\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\r\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\r\n",
        ")\r\n",
        "decoder_states = [state_h_dec, state_c_dec]\r\n",
        "decoder_dense = model.layers[4]\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\r\n",
        "decoder_model = keras.Model(\r\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\r\n",
        ")\r\n",
        "\r\n",
        "# Reverse-lookup token index to decode sequences back to\r\n",
        "# something readable.\r\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\r\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFi1l0NvrVBN",
        "outputId": "3a290e98-a5ed-4eaa-e399-68cac8097597"
      },
      "source": [
        "decoder_lstm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.recurrent_v2.LSTM at 0x7f1dc27c5d30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcKoo_stptF2",
        "outputId": "e18221cf-3407-42af-cf28-3a5843a0d571"
      },
      "source": [
        "decoder_inputs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, None, 154])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw-2SRnKq11f",
        "outputId": "c2b2af1b-f1d4-4b54-a033-e69ea6ac61fa"
      },
      "source": [
        "decoder_states_inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_5')>,\n",
              " <KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'input_6')>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuSdspZ2h8Km"
      },
      "source": [
        "\r\n",
        "def decode_sequence(input_seq):\r\n",
        "    # Encode the input as state vectors.\r\n",
        "    states_value = encoder_model.predict(input_seq)\r\n",
        "\r\n",
        "    # Generate empty target sequence of length 1.\r\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\r\n",
        "    # Populate the first character of target sequence with the start character.\r\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\r\n",
        "\r\n",
        "    # Sampling loop for a batch of sequences\r\n",
        "    # (to simplify, here we assume a batch of size 1).\r\n",
        "    stop_condition = False\r\n",
        "    decoded_sentence = \"\"\r\n",
        "    while not stop_condition:\r\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\r\n",
        "\r\n",
        "        # Sample a token\r\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\r\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\r\n",
        "        decoded_sentence += sampled_char\r\n",
        "\r\n",
        "        # Exit condition: either hit max length\r\n",
        "        # or find stop character.\r\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\r\n",
        "            stop_condition = True\r\n",
        "\r\n",
        "        # Update the target sequence (of length 1).\r\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\r\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\r\n",
        "\r\n",
        "        # Update states\r\n",
        "        states_value = [h, c]\r\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJWOr0Cxh_Cy",
        "outputId": "9c00f009-62a2-4c73-ccda-2cb027282cce"
      },
      "source": [
        "for seq_index in range(20):\r\n",
        "    # Take one sequence (part of the training set)\r\n",
        "    # for trying out decoding.\r\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\r\n",
        "    decoded_sentence = decode_sequence(input_seq)\r\n",
        "    print(\"-\")\r\n",
        "    print(\"Input sentence:\", input_text[seq_index])\r\n",
        "    print(\"Decoded sentence:\", decoded_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Give your application an accessibility workout\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Accerciser Accessibility Explorer\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: The default plugin layout for the bottom panel\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: The default plugin layout for the top panel\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: A list of plugins that are disabled by default\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Highlight duration\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: The duration of the highlight box when selecting accessible nodes\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Highlight border color\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: The color and opacity of the highlight border.\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Highlight fill color\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: The color and opacity of the highlight fill.\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: API Browser\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Browse the various methods of the current accessible\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Hide private attributes\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Method\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Property\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Value\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: IPython Console\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Interactive console for manipulating currently selected accessible\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n",
            "-\n",
            "Input sentence: Event monitor\n",
            "Decoded sentence: प्रोजेक्ट बंद करें\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZnDSL4Ain0I"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}